@misc{liu2024visualwebbench,
      title={VisualWebBench: How Far Have Multimodal LLMs Evolved in Web Page Understanding and Grounding?}, 
      author={Junpeng Liu and Yifan Song and Bill Yuchen Lin and Wai Lam and Graham Neubig and Yuanzhi Li and Xiang Yue},
      year={2024},
      eprint={2404.05955},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{chen2024mmrevaluatingreadingability,
      title={MMR: Evaluating Reading Ability of Large Multimodal Models}, 
      author={Jian Chen and Ruiyi Zhang and Yufan Zhou and Ryan Rossi and Jiuxiang Gu and Changyou Chen},
      year={2024},
      eprint={2408.14594},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2408.14594}, 
}

@misc{zhang2024lmmsevalrealitycheckevaluation,
      title={LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models}, 
      author={Kaichen Zhang and Bo Li and Peiyuan Zhang and Fanyi Pu and Joshua Adrian Cahyono and Kairui Hu and Shuai Liu and Yuanhan Zhang and Jingkang Yang and Chunyuan Li and Ziwei Liu},
      year={2024},
      eprint={2407.12772},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12772}, 
}

@misc{lee2024troltraversallayerslarge,
      title={TroL: Traversal of Layers for Large Language and Vision Models}, 
      author={Byung-Kwan Lee and Sangyun Chung and Chae Won Kim and Beomchan Park and Yong Man Ro},
      year={2024},
      eprint={2406.12246},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.12246}, 
}

@misc{koh2024treesearchlanguagemodel,
      title={Tree Search for Language Model Agents}, 
      author={Jing Yu Koh and Stephen McAleer and Daniel Fried and Ruslan Salakhutdinov},
      year={2024},
      eprint={2407.01476},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.01476}, 
}

@article{zhou2023webarena,
  title={Webarena: A realistic web environment for building autonomous agents},
  author={Zhou, Shuyan and Xu, Frank F and Zhu, Hao and Zhou, Xuhui and Lo, Robert and Sridhar, Abishek and Cheng, Xianyi and Ou, Tianyue and Bisk, Yonatan and Fried, Daniel and others},
  journal={arXiv preprint arXiv:2307.13854},
  year={2023}
}

@article{koh2024visualwebarena,
  title={Visualwebarena: Evaluating multimodal agents on realistic visual web tasks},
  author={Koh, Jing Yu and Lo, Robert and Jang, Lawrence and Duvvur, Vikram and Lim, Ming Chong and Huang, Po-Yu and Neubig, Graham and Zhou, Shuyan and Salakhutdinov, Ruslan and Fried, Daniel},
  journal={arXiv preprint arXiv:2401.13649},
  year={2024}
}

@article{deng2024mind2web,
  title={Mind2web: Towards a generalist agent for the web},
  author={Deng, Xiang and Gu, Yu and Zheng, Boyuan and Chen, Shijie and Stevens, Sam and Wang, Boshi and Sun, Huan and Su, Yu},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{yang2023set,
  title={Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v},
  author={Yang, Jianwei and Zhang, Hao and Li, Feng and Zou, Xueyan and Li, Chunyuan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.11441},
  year={2023}
}

@article{yang2023set,
  title={Set-of-mark prompting unleashes extraordinary visual grounding in gpt-4v},
  author={Yang, Jianwei and Zhang, Hao and Li, Feng and Zou, Xueyan and Li, Chunyuan and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2310.11441},
  year={2023}
}